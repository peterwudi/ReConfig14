%
\documentclass[conference]{IEEEtran}

\usepackage{graphicx}
\usepackage{amsmath,epsfig, url}
\usepackage[justification=centering]{caption}
\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = magenta %Colour of citations
}


\hyphenation{Tam-pe-re micro-soft}


\newcommand{\kfig}[4]{ % params: file, label, caption
        \begin{figure}[!t]
        \centering
        \includegraphics[#4]{Figures/#1}
        \vspace{-1mm}
        \caption{#3}
        \label{#2}
        \end{figure}
}



\begin{document}

% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Advanced Branch Predictors for Soft Processors}


\author{\IEEEauthorblockN{Di Wu and Andreas Moshovos}
\IEEEauthorblockA{Electrical and Computer Engineering Department\\
University of Toronto}
\IEEEauthorblockA{peterwudi.wu@utoronto.ca, moshovos@eecg.toronto.edu}}

% make the title area
\maketitle


\begin{abstract}
The abstract goes here.


\end{abstract}


\IEEEpeerreviewmaketitle


\section{Introduction}
\label{sec:intro}
Field Programmable Gate Arrays (FPGAs) are increasingly being used in embedded and other systems. Such designs often employ one or more embedded microprocessors, and there is a trend to migrate these microprocessors to the FPGA platform primarily for reducing cost. While these soft processors cannot typically match the performance of a hard processor, soft processors are flexible allowing designers to implement the exact number of processors desired, to customize them thus efficiently fitting the application's requirements.

Current commercial soft processors such as Altera's Nios~II~\cite{niosii} and Xilinx's Microblaze~\cite{microblaze} are in-order pipelines with five to six pipeline stages. These processors are often used for less computation-intensive applications, for instance, system control tasks. To support more compute-intensive applications, a key technique to improve performance is branch prediction. Branch prediction has been extensively studied, mostly in the context of application specific custom logic (ASIC) implementations. However, na\"ively porting ASIC-based branch predictors to FPGAs results in slow and/or resource-inefficient implementations since the tradeoffs are different for reconfigurable logic. Wu et al.~\cite{grselect} have shown that a branch predictor design for soft processors should balance its prediction accuracy as well as its maximum operating frequency. They proposed an FPGA-friendly minimalistic branch prediction implementation \textit{gRselect} for Altera's highest performing soft-processor Nios~II-f.

Wu et al. limited the hardware budget of the gRselect predictor to just one M9K Block RAM~\cite{StratixIVM9K} on Altera Stratix IV devices; Altera's NIOS II-f also uses just a single M9K block RAM. Such a small hardware budget prohibits more elaborate and potentially more accurate, state-of-the-art branch prediction schemes such as Perceptron~\cite{perceptron} and TAGE~\cite{tage}. Accordingly, this work relaxes the hardware budget constraint and investigates FPGA-friendly implementations of Perceptron and TAGE predictors. It studies their accuracy and speed as a function of hardware budget.  

Specifically, this work makes the following contributions: (1)~It studies the FPGA implementation of the Perceptron and TAGE predictors. It optimizes perceptron's maximum operating frequency by introducing techniques such as including a compliment weight table to simplify multiplication and Low Order Bit (LOB) Elimination for faster summation. (2)~It compares the branch direction prediction accuracy of the predictors showing that compared to the previously proposed gRselect, perceptron is \~1\% worse while TAGE is \~1\% better, assuming these predictors can be accessed in a single cycle. (3)~It finds that TAGE is too slow for single-cycle access. Accordingly, this work proposes an overriding predictor \mbox{O-TAGE-SC} that uses a simple base predictor to provide a base prediction in the first cycle, which can be overridden in the second cycle should TAGE disagree with the base predictor. It shows that \mbox{O-TAGE-SC} achieves 5.2\% better instruction throughput over gRselect.

\section{Background and Goals}
\label{sec:background}

% Di: this section is based on the background section from the grselect paper. I've removed/modified some details not relevant to this paper (BTB and RAS), but the paragraph is mostly the same. I'm leaving it this way for now, probably should rephrase the paragraph later?

Fig.~\ref{fig:bpcanonical} shows the organization of a typical branch predictor comprising a direction predictor and a target predictor.  The predictor operates in the fetch stage where it aims to predict the program counter (PC), that is the address in memory, of the instruction to fetch in the next cycle using the current instruction's PC and other dynamically collected information. The \textit{direction} predictor guesses whether the branch will be taken or not. The \textit{target} predictor guesses the address for predicted as taken branches and often includes a \textit{stack} predictor for predicting function returns. The multiplexer at the end selects based on the branch type and the direction prediction whether the target is the fall through address (PC+4 in Nios~II) or the target predicted by the target or stack predictor. Since, at this point in time, the actual instruction is not available in a typical ASIC implementation, it is not directly possible to determine whether the instruction is a return, a branch, or some other instruction. Accordingly, a Selection Logic block uses either pre-decode information or a PC-based, dynamically populated lookup table to guess which target is best to use. With the latter scheme, when no entry exists in the lookup table, some default action is taken until the first time a branch is encountered. Once the branch executes, its type is stored in the lookup table where it serves to identify the branch type on subsequent encounters. Due to limited capacity multiple branches may map onto the same prediction entries. This \textit{aliasing} tends to reduce accuracy.
\kfig{bpcanonical.pdf}{fig:bpcanonical}{Canonical Branch Predictor.}{angle = 0, trim = 0.2in 1.7in 0.4in 0.1in, clip, width=0.4\textwidth}

\subsection{Design Goals}
\label{sec:background:goal}

This work aims to implement a Perceptron and a TAGE predictors that operate at a high operating frequency while achieving high accuracy so that they improve execution performance. As section~\ref{sec:scheme:tage} will show, a single-cycle TAGE is prohibitively slow. Therefore, this work considers an overriding TAGE predictor that produces a base prediction in one cycle while overriding that decision with a better prediction in the second cycle if necessary. Perceptron and TAGE both require large tables. Accordingly, this work investigates how their accuracy and latency vary with the amount of hardware resources they are allowed to use.

\section{Branch Prediction Schemes}
\label{sec:scheme}
This section discusses the structure of the branch predictors considered: (1)\ the Perceptron and (2)\ TAGE direction predictors and (3) the target predictor. Sections~\ref{sec:scheme:perceptron} and~\ref{sec:scheme:tage} discuss Perceptron and TAGE, while section~\ref{sec:scheme:target} discusses the target predictor.

\subsection{Perceptron Predictor}
\label{sec:scheme:perceptron}
The perceptron predictor use vectors of weights (i.e., perceptrons) to represent correlations among branch instructions~\cite{perceptron}. Fig.~\ref{fig:perceptron} shows the structure of a Perceptron predictor. When making a prediction, a weight vector is read from the table using a hash function of the instruction's PC. Then, each weight is multiplied by 1 if the corresponding global branch history is taken, and by -1 otherwise. Finally, the resulting products are summed up and the Perceptron predicts taken if the sum is positive, and not taken otherwise.
\kfig{perceptron.pdf}{fig:perceptron}{The preceptron branch predictor.}{angle = 0, trim = 1in 3.5in 2in 1in, clip, width=0.4\textwidth}

\subsection{Tagged Geometric History Length Branch Predictor}
\label{sec:scheme:tage}
The TAGE predictor features a bimodal predictor as a base predictor $T_0$ to provide a basic prediction and a set of $M$ tagged predictor components $T_i$~\cite{tage}. These tagged predictor components $T_i$, where $1\leq i\leq M$, are indexed with hash functions of the branch address and the global branch/path history and of various lengths. The global history lengths used for computing the indexing functions for tables $T_i$ form a geometric series, i.e., $L(i) = (int)(\alpha^{i{}^{\_}1}\times L(1)+0.5)$. TAGE achieves its high accuracy by utilizing very long history lengths judiciously.

Fig.~\ref{fig:tage} shows a 5-component TAGE predictor. Each table entry has a 3-bit saturating counter \textit{ctr} for the prediction result, a \textit{tag}, and a 2-bit useful counter \textit{u}. The table indices are produced by hashing the PC and the global history using different lengths per table. All tables are accessed in parallel and each table provides a valid prediction only on a tag match. The final prediction comes from the matching tagged predictor component that uses the longest history. \kfig{tage.pdf}{fig:tage}{A 5-component TAGE branch predictor.}{angle = 0, trim = 0.6in 0.6in 0.4in 0.2in, clip, width=0.4\textwidth}


\subsection{Branch Target Predictor}
\label{sec:scheme:target}
Branch Target Prediction usually requires a Branch Target Buffer (BTB), a cache-like structure that records the addresses of the branches and the target addresses associated with them. If a branch is predicted to be taken and there is also a BTB hit, then the next PC is set to be the predicted target. A BTB can be set-associative to reduce aliasing.

Another common structure used for branch target prediction is the Return Address Stack (RAS). It is a stack-like structure that predicts the target address of function returns. When a call instruction executes, the return address of that call is pushed onto the RAS. When the processor executes the corresponding return instruction, RAS pops the return address and provides a prediction. The prediction is accurate as long as  the RAS' size\ is less then the current call depth. Most modern processors have a shallow RAS because typical programs generally do not have very deep call depths. RAS will fail to provide correct target prediction if it overflows.

Wu et al. has shown that with  the same hardware budget as Nios~II-f (i.e., 1 M9K BRAM), eliminating the BTB and using \textit{Full Address Calculation} (FAC) together with a RAS results in better performance~\cite{grselect}. FAC  calculates the target address in the fetch stage and accurately predicts the target addresses for direct branches, whose target can be calculated based on the instruction itself~\cite{niosii}. Wu et al. has shown that direct branches and returns comprise over 99.8\% of all branches. Implementing FAC with RAS can cover these branches with 100\% accuracy, therefore having a BTB to cover all branches results in negligible improvement in target prediction accuracy. On the other hand, eliminating the BTB and dedicating the entire BRAM for direction prediction improves direction prediction accuracy significantly.

Since, this work investigates how branch prediction accuracy can improve when additional hardware resources are used,  adding a BTB for better target prediction coverage could improve target prediction accuracy. Accordingly, we reconsider introducing a BTB. However, simulations show that the accuracy is still better without a BTB. This is because when the target predictor only has FAC and RAS, it never predicts indirect branches that are not returns because it is not capable to do so. As a result, the destructive aliasing in the \textbf{direction} predictor is alleviated because less branches are being predicted. Based on this observation, this work uses FAC with RAS as the branch target predictor.


\section{FPGA Implementation Optimizations}
\label{sec:fpga}
This section discusses FPGA-specific implementation optimizations for Perceptron and TAGE. While this section assumes a modern Altera FPGA, the optimizations presented should be broadly applicable.

\subsection{Perceptron Implementation}
\label{sec:fpga:perceptron}

Section~\ref{sec:scheme:perceptron} explained that the Perceptron predictor maintains vectors of weights in a table. It produces a prediction through the following steps: (1)~a \textit{perceptron}, that is a vector of weights, is read from the table. (2)~the weights are multipled with factors chosen based on the the corresponding global history bits. The weights are 1 for taken and -1 for not-taken. (3)~The resulting products are summed up and a prediction is made based on the sign of the result; predict taken if the sum is positive, and not-taken otherwise. Formally, for a Perceptron predictor using $h$ history bits, each weight vector has $h$ weights $w_{0...h}$, where the bias constant $w_0 = 1$. The predictor has to calculate $y = w_0 + \sum_{i=1}^{h} G_iw_i$, and predict taken if $y$ is positive and not-taken otherwise.

Each of these steps poses difficulties to map to an FPGA substrate. The rest of this section addresses these problems.

\subsubsection{Perceptron Table Organization}
\label{sec:fpga:perceptron:table}
Each weight in a perceptron is typically 8-bit wide, and Perceptron predictors usually use at least a 12-bit global history~\cite{perceptron}. The depth of the table, on the other hand, tends to be relatively shallower (e.g., 64 entries for 1KB hardware budget). This requires a very wide but shallow memory, which does not map well to BRAMs on FPGAs. For example, the widest configuration of a M9K BRAM on Altera Stratix IV is 36-bit wide times 1k entries~\cite{StratixIVM9K}. If we implement the 1KB Perceptron as proposed by Jim\'enez et al.~\cite{perceptron}, which uses 96-bit wide perceptrons with 12-bit global history, it will result in a huge resource inefficiency as shown in Fig~\ref{fig:perceptronTable}. Stratix IV chips have another larger but slower and fewer M144K BRAM on Stratix IV chips~\cite{StratixIVM9K}, which can be configured as wide as 72-bit times 2K entries, clearly the inefficiency problem persists and it would impact maximum operating frequency.

Since typically the Perceptron table does not require large storage space, the proposed Perceptron implementation uses MLABs as storage, which are fast fine-grain distributed memory resources. Since 50\% of all LABs can be configured as MLAB on Altera Stratix IV devices, using MLABs does not introduce routing difficulty.
\kfig{perceptronTable.pdf}{fig:perceptronTable}{Inefficiency using M9K BRAMs to implement wide but shallow perceptron tables.}{angle = 0, trim = 1in 2in 3.4in 0.5in, clip, width=0.3\textwidth}


\subsubsection{Multiplication}
\label{sec:fpga:perceptron:mult}
The multiplication stage calculates the products of a weights in a perceptron and their global direction histories. Since the value of the global direction history can only be either 1 or -1, the ``multiplication'' degenerates to two cases, i.e., each product can either be the true form or the 2's compliment (i.e., negative) form of each weight. A straightforward implementation calculates the negative of each weight and uses a mux to select, using the corresponding global history bit, the appropriate result, as Fig.~\ref{fig:perceptronMult}(a) shows. To improve operating frequency, when updating the perceptron in the execution stage where the branch is resolved, both positive and negative forms of the updated weight can be pre-calculated, and the negatives can be stored on a complement perceptron table. In this way, the multiplication stage requires only a 2-to-1 mux, as Fig.~\ref{fig:perceptronMult}(b) shows. This optimization trade offs increase resources (it requires extra storage for the negative weights) for improved speed.
\kfig{perceptronMult.pdf}{fig:perceptronMult}{Perceptron multiplication implementation.}{angle = 0, trim = 0.3in 2in 3in 0.6in, clip, width=0.4\textwidth}

\subsubsection{Adder Tree}
\label{sec:fpga:perceptron:adder}
The adder tree sums the products from the multiplication stage. As Section~\ref{sec:eval:ipc} will show, a global history of at least 16 bits has to be used to achieve sufficient accuracy. Implementing a 16-to-1 adder tree for 8-bit integers na\"ively degrades maximum frequency severely. The maximum frequency has to be improved for Perceptron to be practical.

This work employs \textit{Low Order Bit (LOB) Elimination} proposed by Aasaraai et al.~\cite{lob}. The idea is to ignore the Low Order Bits (LOBs) of each weight and only use the High Order Bits (HOBs) during prediction, while still using all the bits dfor updates. Section~\ref{sec:eval:ipc} shows that eliminating 5 LOB bits is only 0.06\% less accurate than using all 8 bits, but summing fewer bits results in significantly higher maximum frequency. Section~\ref{sec:eval:perf} will show that using 3 HOB for prediction achieves the best overall performance.

Cadenas et al.~\cite{perceptronRearrange} proposed a method to rearrange the weights stored in the table in order to reduce the number of layers of the adder tree. Assuming a Perceptron predictor uses $h$ history bits, instead of storing $h$ weights $w_i$ where $i = 1 ... h$, a new form of weights $\widetilde{w}_i$: $\widetilde{w}_i = - w_i + w_{i+1};, \widetilde{w}_{i+1} = - w_i - w_{i+1},$ for $i = 1, 3, ..., h-1$ is used. The perceptron prediction can now be computed by $y = w_0 + \sum_{i=1}^{h/2}(-G_{2i-1})\widetilde{w}_{2i+G_{2i-1}G_{2i}}$. This work applies this new arrangement because it pushes part of the calculation to the less time critical update logic of the Perceptron predictor so that only $h/2$ additions have to be performed, hence reduces the number of adders required by 50\%.

Using fast adders such as carry-lookahead adders does not help to reduce the adder tree latency. This is because that the problem is not summing a few very wide numbers, but many narrow numbers. Most of the latency comes from going through layers of the adders rather than propagating the carry bits. To further improve maximum frequency, this work adapts the implementation of a Wallace Tree~\cite{wallacetree}. A Wallace tree is a hardware implementation of a digital circuit that efficiently sums the partial products when multiplying two integers, which is similar to the situation that a Perceptron predictor is facing. The Wallace tree implementation proves to be 10\% faster than a na\''ive binary reduction tree implementation. 

\subsection{TAGE Implementation}
\label{sec:fpga:tage}
Section~\ref{sec:eval:ipc} shows that TAGE  is the most accurate amongst all the direction predictors considered in this work when they use the same hardware budget. However, TAGE uses multiple tables with tagged entries that require comparator driven logic which does not map well onto FPGAs. Section~\ref{sec:eval:perf} shows that the maximum frequency slowdown of TAGE is not amortized by the resulting accuracy gains. Accordingly, TAGE is best used as an overriding predictor.

The critical path of TAGE is as follows: (1)~It performs an elaborate PC-based hashing to generate multiple table indices one per table. (2)~It accesses the tables and in parallel compares the tags of the read entries to determine whether they match. (3)~Finally each decision has to fall through cascaded layers of multiplexers to select the longest matching prediction. Although the latency of these operations is high, the path can be easily pipelined to achieve much higher operating frequency. Based on this observation, this work explores an overriding branch predictor implementation using TAGE. Overriding branch prediction is a technique to leverage the benefits of both fast but less accurate, and slow but more accurate predictors. This technique has been used commercially, e.g., in the Alpha EV8~\cite{alphaEV8} microprocessors. In an overriding predictor, a faster but less accurate base predictor makes a base prediction quickly, and then a slower but more accurate predictor overrides that decision if it disagrees with the base prediction. 

In this work, the base predictor is the simple bimodal predictor included in TAGE it self, i.e., $T_0$ in Fig.~\ref{fig:tage}. The bimodal predictor provides a base prediction in the first cycle, and TAGE provides a prediction at the second cycle. Section~\ref{sec:eval:ipc} and~\ref{sec:eval:fmax} show that the overriding TAGE outperforms all the other branch prediction schemes in terms of both accuracy and maximum frequency.

\section{Evaluation}
\label{sec:eval}
This section evaluates the branch predictors. Section~\ref{sec:eval:methodology} details the experimental methodology. Section~\ref{sec:eval:ipc} compares the accuracy of the various direction predictors: bimodal, gshare, gRselect, Perceptron and TAGE. It shows that the overriding TAGE is the most accurate. Section~\ref{sec:eval:fmax} reports the maximum operating frequency as well as the FPGA resource usage. Finally, Section~\ref{sec:eval:perf} reports the overall performance, showing that the overriding TAGE predictor is the best performing predictor.

As Section~\ref{sec:scheme:target} discussed, all configurations use the same target prediction scheme, which includes a FAC and RAS, the same target predictor used in the gRselect predictor~\cite{grselect}.

\subsection{Methodology}
\label{sec:eval:methodology}
% Di: mostly based on the grselect paper, rephrase?
To compare the predictors this work measures: (1) the Instruction Per Cycle (IPC) instruction execution rate, a frequency agnostic metric that better reflects the accuracy of each predictor factoring away their latency, (2) Instructions Per Second (IPS), a true measure of performance which takes the operating frequency into account, (4) Operating frequency, and (5) resource usage. Simulation measures IPC using a custom, cycle-accurate, full-system Nios~II simulator. The simulator boots ucLinux~\cite{uclinux}, and runs a subset of SPEC CPU2006 integer benchmarks with reference inputs~\cite{spec2k6}.

The baseline predictors considered are: (1) bimodal, (@)\ gshare and (3)\ gRselect. These predictors are implemented to match as closely as possible the implementations of Wu et al.~\cite{grselect}. All designs were implemented in Verilog and synthesized using Quartus II 13.0 on a Stratix IV EP4SE230F29C2 chip in order to measure their maximum clock frequency and area cost. The maximum frequency is reported as the average maximum clock frequency of five placement and routing passes with different random seeds. Area usage is reported in terms of ALUTs used.


\subsection{Branch Prediction Accuracy}
\label{sec:eval:ipc}
This section first presents data that justify the final design of Perceptron and TAGE configurations, then a comparison versus bimodal, gshare and gRselect is presented.

\subsubsection{Perceptron}
\label{sec:eval:ipc:perceptron}
This work considers Perceptron predictor with a hardware budget ranging from 1KB to 32KB. For each hardware budget, this work also considers different configurations varying the number of global history bits used. Fig.~\ref{fig:perceptronIPC} shows the best performing Perceptron configuration for each hardware budget. The most accurate Perceptron configuration uses a16KB budget. \textbf{GOT\ TO\ EXPLAIN\ WHY\ MORE\ RESULTS\ IN\ LESS\ ACCURACY. OTHERWISE, THE\ REVIEWERS\ WILL\ THINK\ THERE\ IS\ A\ PROBEM\ WITH\ YOUR\ IMPLEMENTATION.\ \ \ }
\kfig{perceptronIPC.pdf}{fig:perceptronIPC}{IPC of the best performing perceptron configuration with various hardware budgets.}{angle = 0, trim = 0.9in 4in 0.8in 4.5in, clip, width=0.4\textwidth}

To determine how many HOBs the predictor should use, we take the most accurate Perceptron configuration and experimented with all possible numbers of HOBs used. Fig.~\ref{fig:perceptronHOB} shows the IPC of this Perceptron when different number of HOBs are used. The data shows that using 3 HOBs results in virtually identical IPC (less than 0.06\% difference) versus using all 8 bits.\ Moreover, the IPC drops significantly when only using 2 HOBs. Therefore the final perceptron design uses 3 HOBs to improve operating frequency without affecting accuracy.
\kfig{perceptronHOB.pdf}{fig:perceptronHOB}{IPC when using different number of HOBs for the most accurate perceptron configuration.}{angle = 0, trim = 1in 1.5in 0.9in 1.7in, clip, width=0.4\textwidth}

The most accurate Perceptron uses 16 global history bits with the arrangement discussed in Section~\ref{sec:fpga:perceptron:adder}, so in the end it only requires space to store eight 8-bit weights $\widetilde{w}_{i}$ for $i = 1...8$ plus 3 HOBs per weight in its 2's complement form. The perceptron table has 1024 entries. Therefore, the total storage used is: $ ((8+ 3)\ bits/weight \times 8\ weights/entry)\times 1024\ entries  = 90,112 bits = 11KB$. 

\subsubsection{TAGE}
\label{sec:eval:ipc:tage}
This work uses the TAGE predictor introduced by Seznec et al.~\ref{tage} \textbf{REFERENCE}.  This work proposes three designs incorporating TAGE:  (1)~the single-cycle TAGE, which requires TAGE to provide a prediction in one cycle (i.e., in the fetch stage), (2)~the Overriding TAGE (O-TAGE), which uses just the bimodal predictor to provide a base prediction in the first cycle, and \textit{always} overrides the base prediction if TAGE disagrees at the end of the second cycle, and (3)~the Overriding TAGE with a Statistical Corrector (\mbox{O-TAGE-SC}), which overrides the prediction only when TAGE\ consistently disagrees over several encounters of the same event.

Specifically,  \mbox{O-TAGE-SC}\ is motivated by Seznec's observation that TAGE fails at predicting branches that are statistically biased towards a direction but not correlated to the history path~\cite{isltage}. On some of these branches, TAGE often performs worse than a simple PC-indexed table, e.g., a bimodal predictor. This may result in many miss-overrides on these type of branches. More importantly, in Nios~II-f where the branch resolution latency is only 2 cycles, the overriding TAGE saves one cycle for each correct override, but loses two cycles for each incorrect override. Hence, the overriding TAGE must make two right decisions for every one wrong decision to break even. Therefore, the overriding TAGE must be very confident to make a overriding decision, which necessitates the statistical corrector.

The statistical corrector we implemented has a small table with 256 entries that is indexed by 8 bits from the PC. Each entry is a 10-bit saturating counter. If TAGE correctly overrides a decision, the corresponding counter is incremented by one, otherwise the counter is \textit{reset} to zero.

Fig.~\ref{fig:tageIPC} shows the IPC of the three designs that incorporate TAGE. It shows that the single-cycle TAGE delivers the highest accuracy, however, as Section~\ref{sec:eval:ips} shows, its high accuracy cannot amortize the slowdown in operating frequency. O-TAGE is much faster, but its accuracy drops significantly. Finally, the accuracy of \mbox{O-TAGE-SC} is within 0.2\% of the single-cycle TAGE.
\kfig{tageIPC.pdf}{fig:tageIPC}{IPC of the three designs incorporating TAGE.}{angle = 0, trim = 1.1in 1.5in 0.9in 1.5in, clip, width=0.4\textwidth}


\subsubsection{Accuracy Comparison}
\label{sec:eval:ipc:comparison}
For fair comparisons, we scale bimodal, gshare and gRselect from 1KB to 32KB, which is the same hardware budget as TAGE and the largest Perceptron considered in this work. Fig.~\ref{fig:adipc} shows the IPC of the best performing configuration of each prediction scheme. All the branch predictors except for Perceptron shown in this figure use 32KB of storage. The 32KB and 16KB Perceptron deliver identical IPC, therefore the 16KB version is selected as the final implementation. The Single-Cycle TAGE is the most accurate, followed by \mbox{O-TAGE-SC} and Gshare. Perceptron's accuracy comes close to gRselect but it is still slightly less accurate.
\kfig{adipc.pdf}{fig:adipc}{IPC of the considered branch predictors.}{angle = 0, trim = 0.9in 2.3in 0.9in 2.3in, clip, width=0.4\textwidth}


\subsection{Frequency}
\label{sec:eval:fmax}
Fig.~\ref{fig:adfmax} shows the maximum operating frequency for each branch prediction scheme and for various hardware budgets. The Single-Cycle TAGE and \mbox{O-TAGE-SC} use 32KB.
\kfig{adfmax.pdf}{fig:adfmax}{Maximum operating frequency of the considered branch prediction schemes with various hardware budget.}{angle = 0, trim = 0.7in 4.5in 0.7in 4.5in, clip, width=0.5\textwidth}

The fastest predictor is \mbox{O-TAGE-SC} operating at 270 MHz, followed by the 1KB Perceptron and the 1KB gRselect. The maximum frequency of gshare, bimodal and Perceptron drops rapidly with increasing size, while gRselect's frequency does not suffer too much. Despite that the logic is larger and more difficult to place and route,  the table indexing of gRselect comes from the GHR register. GRselect reads a wide entry and then using bits form the PC\ to select the appropriate ones. The indexing of gshare, bimodal and Perceptron comes from the predicted PC which. The PC  is both the input and the output of the branch predictor. This loop forms the critical path of gshare, bimodal and Perceptron, which quickly gets slower as the size of the predictors increase. The Single-Cycle TAGE operates at 222MHz, which is \~15\% slower than the 1KB gRselect and \~18\% slower than \mbox{O-TAGE-SC}.



\subsection{Performance}
\label{sec:eval:perf}
IPC is a measurement that does not take operating frequency into consideration. The actual performance of a processor is measured by Instruction Per Second (IPS), which is the product of IPC and the maximum operating frequency. Fig.~\ref{fig:adips} reports the overall performance in terms of IPS. This experiment assumes a 270 MHz maximum clock frequency for the processor, the maximum clock frequency of Nios~II-f on Stratix IV C2 speed grade devices~\cite{niosfmax}.
\textbf{THE REVIEWERS\ MAY\ QUESTION\ WHY\ YOU\ INCLUDE\ ONLY\ THE\ SMALL\ GRSELECT\ AND\ OTHER\ BASELINE\ PREDICTORS. I\ DON"T\ THKNK\ YOU\ EVER\ EXXPLICITY\  STATE\ THET\ THETY\ ARE\ WORSE. MAY\ BE\ INCLUDE\ THEM?\ }\kfig{adips.pdf}{fig:adips}{Processor IPS comparison with various predictors.}{angle = 0, trim = 1in 1.8in 0.7in 1.8in, clip, width=0.5\textwidth}

The best performing predictor is \mbox{O-TAGE-SC}, which delivers 5.2\% higher IPS than the 1KB gRselect. Although the Single-Cycle TAGE is the most accurate, its IPS is the lowest because its latency is too high. The 1KB perceptron ends up 0.2\% better than the 1KB gRselect, because of the optimization efforts into improving its frequency. 

% Di: should I compare area? should area comparison include memory bits? Perceptron does not use BRAMs, but MLABs

\subsection{Increasing Branch Resolution Latency}
\label{sec:eval:brresolvelatency}
As discussed in Section~\ref{sec:eval:ipc:tage}, the branch resolution latency is so short that \mbox{O-TAGE-SC} has to make at least two correct overrides for every incorrect overrides just to break even. Even with this harsh condition, \mbox{O-TAGE-SC} is still 1.1\% more accurate than the 1KB gRselect. Some processor designs may choose to use a deeper pipeline to improve operating frequency and performance. Accordingly, the branch resolution latency may increase. Assuming that the branch resolution latency is $n$ cycles where $n > 1$, the required ratio of correct and incorrect overrides is $n/(n-1)$, which approaches 1 as $n$ gets larger. As a result,  the performance gap between \mbox{O-TAGE-SC} and gRselect can get larger. Fig.~\ref{fig:brresolve} shows the IPS of the 1KB gRselect and \mbox{O-TAGE-SC} in a Nios~II processor that requires more than two cycles to resolve a branch. 
\kfig{brresolve.pdf}{fig:brresolve}{xxxxxxxxxxxxxx??????????????.}{angle = 0, trim = 1in 1in 0.7in 1.5in, clip, width=0.4\textwidth}

There is a trend to scale soft processors to support more computation-intensive applications, inevitably the pipeline of soft processors will get deeper. 
% Di: no clue what conclusion we can draw from this...



\section{Conclusion}
The conclusion goes here.




% references section
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,bp}





% that's all folks
\end{document}


